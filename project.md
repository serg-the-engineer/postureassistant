План Проектирования: Утилита-помощник для контроля осанки
1. Executive Summary & Goals
Цель данного плана — спроектировать и описать этапы создания десктопного приложения, которое помогает пользователям поддерживать правильную осанку во время работы за компьютером. Приложение будет использовать веб-камеру для анализа положения головы в реальном времени.
Ключевые цели:
Создать MVP (Minimum Viable Product): Разработать базовую версию приложения, которая захватывает видеопоток, определяет положение головы и отображает в окне простой индикатор правильности осанки.
Заложить масштабируемую архитектуру: Спроектировать систему так, чтобы в будущем можно было легко добавить функции уведомлений и сбора статистики без кардинального рефакторинга.
Обеспечить приемлемую производительность и приватность: Убедиться, что обработка видео не перегружает систему пользователя, а все данные обрабатываются локально.
2. Current Situation Analysis
Проект создается с нуля. Существующая кодовая база или архитектура отсутствуют. Это дает возможность спроектировать систему в соответствии с лучшими практиками без ограничений, накладываемых унаследованным кодом.
3. Proposed Solution / Refactoring Strategy
3.1. High-Level Design / Architectural Overview
Предлагается модульная архитектура с четким разделением ответственности между компонентами. Это обеспечит гибкость, тестируемость и простоту добавления нового функционала.
Основная идея — отделить логику захвата видео, его обработки и отображения пользовательского интерфейса. Взаимодействие между модулями будет происходить через четко определенные интерфейсы и систему событий.
Generated mermaid
graph TD
    subgraph "Пользовательский Интерфейс (UI Layer)"
        A[MainWindow] -- управляет --> B(Настройки калибровки)
        A -- отображает статус --> C{Индикатор Осанки}
        A -- отображает (опц.) --> D[Видеопоток]
    end

    subgraph "Ядро Приложения (Core Layer)"
        E[ApplicationCore] -- запускает/останавливает --> F & G & H
        F(CameraService) -- поставляет кадры --> G(ProcessingService)
        G -- определяет лицо --> I{FaceDetector}
        G -- анализирует положение --> J{PostureAnalyzer}
        G -- отправляет событие о смене статуса --> E
        H(SettingsService) -- предоставляет зону --> J
    end

    subgraph "Будущие Модули"
        K(NotificationService)
        L(StatisticsService)
    end

    E -- передает событие статуса --> A
    E -- передает событие статуса (в будущем) --> K
    E -- передает событие статуса (в будущем) --> L
    B -- сохраняет/загружает --> H
Use code with caution.
Mermaid
Диаграмма: Показывает, что CameraService поставляет кадры в ProcessingService. ProcessingService использует FaceDetector и PostureAnalyzer для определения статуса осанки и отправляет результат в ApplicationCore. ApplicationCore уведомляет MainWindow для обновления UI. Будущие сервисы (NotificationService, StatisticsService) будут так же получать уведомления от ApplicationCore.
3.2. Key Components / Modules
ApplicationCore (Ядро приложения): Оркестратор. Инициализирует и связывает все сервисы. Управляет жизненным циклом приложения и служит шиной событий для взаимодействия модулей.
CameraService (Сервис камеры): Отвечает за обнаружение доступных камер, подключение к выбранной камере и захват видеокадров с заданной частотой. Предоставляет кадры для дальнейшей обработки.
ProcessingService (Сервис обработки): Сердце приложения.
Получает кадры от CameraService.
Использует библиотеку компьютерного зрения (например, OpenCV) для обнаружения лица на кадре.
Анализирует положение обнаруженного лица (координаты верхней части головы) относительно "правильной" зоны, заданной в настройках.
Генерирует события о состоянии осанки (Correct, Incorrect, NotDetected).
UIService / MainWindow (Пользовательский интерфейс):
Отображает главное окно приложения.
Предоставляет элементы управления для запуска/остановки мониторинга и калибровки.
Визуализирует текущий статус осанки (например, изменение цвета иконки).
Опционально может отображать видеопоток с камеры для удобства калибровки.
SettingsService (Сервис настроек):
Управляет сохранением и загрузкой пользовательских настроек.
Ключевая настройка: координаты и размеры "правильной" зоны для головы.
Сохраняет настройки в локальном файле (например, JSON или XML).
3.3. Detailed Action Plan / Phases
Phase 1: Создание MVP (Core Functionality)
Objective(s): Реализовать базовую, но полностью рабочую версию приложения.
Priority: High
Task 1.1: Выбор технологического стека и настройка проекта
Rationale/Goal: Определить ключевые технологии, которые повлияют на всю дальнейшую разработку.
Estimated Effort: S
Deliverable/Criteria for Completion: Создан пустой проект. Выбрана и обоснована платформа (например, Qt/C++ для производительности и нативности или Electron/TypeScript для скорости разработки UI) и библиотека компьютерного зрения (OpenCV как надежный стандарт). Настроен CI/CD пайплайн.
Task 1.2: Реализация CameraService
Rationale/Goal: Получить доступ к камере и научиться захватывать видеокадры.
Estimated Effort: M
Deliverable/Criteria for Completion: Сервис может найти системную камеру, подключиться к ней и передавать кадры в виде объектов (например, cv::Mat) с ограниченной частотой (например, 10 FPS) в отдельном потоке.
Task 1.3: Реализация ProcessingService с интеграцией детектора лиц
Rationale/Goal: Реализовать ключевую логику анализа изображений.
Estimated Effort: M
Deliverable/Criteria for Completion: Сервис получает кадры, использует OpenCV (например, каскады Хаара или легковесную DNN-модель) для обнаружения прямоугольника лица на кадре.
Task 1.4: Реализация базового UI (MainWindow)
Rationale/Goal: Создать окно для взаимодействия с пользователем.
Estimated Effort: M
Deliverable/Criteria for Completion: Создано окно с кнопками "Старт/Стоп", местом для индикатора статуса и (опционально) областью для вывода видео с камеры. UI не должен "зависать" во время работы обработки.
Task 1.5: Реализация логики анализа осанки и калибровки
Rationale/Goal: Определить, что такое "правильная" осанка, и позволить пользователю настроить это.
Estimated Effort: S
Deliverable/Criteria for Completion: Реализован режим калибровки: пользователь садится ровно, нажимает кнопку "Калибровать", и приложение запоминает текущее положение верхней границы лица как эталонное. Реализован SettingsService для сохранения этой информации. ProcessingService сравнивает текущее положение с эталонным.
Task 1.6: Интеграция всех компонентов
Rationale/Goal: Собрать все части вместе в работающее приложение.
Estimated Effort: M
Deliverable/Criteria for Completion: Приложение запускается. По кнопке "Старт" начинается захват видео и анализ. Индикатор в UI меняет цвет/текст в зависимости от того, находится ли голова пользователя в пределах откалиброванной зоны.
Phase 2: Уведомления и статистика (Future Features)
Objective(s): Реализовать функционал, повышающий ценность продукта для пользователя.
Priority: Medium
Task 2.1: Реализация NotificationService
Rationale/Goal: Предоставить пользователю обратную связь, даже когда приложение свернуто.
Estimated Effort: M
Deliverable/Criteria for Completion: При переходе статуса осанки в Incorrect на продолжительное время (например, 10 секунд), сервис отправляет системное уведомление.
Task 2.2: Проектирование и реализация StatisticsService
Rationale/Goal: Собирать данные для анализа пользователем своих привычек.
Estimated Effort: L
Deliverable/Criteria for Completion: StatisticsService подписывается на события смены статуса и записывает временные метки в локальное хранилище (например, SQLite базу данных). Реализован UI для просмотра простой статистики (например, круговая диаграмма "% времени с хорошей/плохой осанкой за сегодня").
3.4. Data Model Changes
Настройки (settings.json):
Generated json
{
  "version": 1,
  "camera_id": "default",
  "calibration_data": {
    "reference_y": 250,
    "tolerance_pixels": 50
  }
}
Use code with caution.
Json
Статистика (схема для SQLite в Фазе 2):
Generated sql
CREATE TABLE posture_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    start_timestamp INTEGER NOT NULL,
    end_timestamp INTEGER NOT NULL,
    duration_seconds INTEGER NOT NULL,
    state TEXT NOT NULL -- 'Correct', 'Incorrect', 'NotDetected'
);
Use code with caution.
SQL
4. Key Considerations & Risk Mitigation
4.1. Technical Risks & Challenges
Риск: Высокое потребление CPU при обработке видео в реальном времени.
Митигация:
Ограничить частоту обработки кадров до 5-10 FPS, что более чем достаточно для отслеживания осанки.
Вынести всю обработку в отдельный рабочий поток, чтобы не блокировать UI.
Использовать легковесные модели для детекции лиц (например, Haar Cascades вместо тяжелых нейронных сетей для MVP).
Риск: Низкая точность или сбои детекции лица (плохое освещение, угол поворота головы).
Митигация:
Для MVP мы ориентируемся на простую метрику (вертикальное положение). Это нужно четко указать пользователю.
Предоставить простой и понятный процесс калибровки.
В будущем можно перейти на более продвинутые библиотеки (например, MediaPipe), которые предоставляют 3D-координаты и более устойчивы к поворотам.
Риск: Вопросы приватности из-за доступа к камере.
Митигация:
Четко заявить, что вся обработка происходит локально на компьютере пользователя.
Никакие изображения или видео не сохраняются и не передаются по сети.
Индикатор в UI должен ясно показывать, когда камера активна.
4.2. Dependencies
Внутренние: ProcessingService зависит от CameraService (поставка кадров) и SettingsService (данные для калибровки). UI зависит от событий, генерируемых ядром приложения.
Внешние:
Выбранный UI-фреймворк (Qt, Electron и т.д.).
Библиотека компьютерного зрения (OpenCV).
Разрешения операционной системы на доступ к камере.
4.3. Non-Functional Requirements (NFRs) Addressed
Производительность: Адресуется через оптимизацию частоты кадров и вынос обработки в отдельный поток. Целевое потребление CPU — менее 15% на среднем современном процессоре.
Масштабируемость/Расширяемость: Модульная архитектура с шиной событий позволяет легко добавлять новые сервисы (NotificationService, StatisticsService), не затрагивая существующие.
Приватность: Адресуется строгим правилом локальной обработки данных.
Надежность: Приложение должно корректно обрабатывать ситуации, когда камера недоступна или лицо не обнаружено, не "падая", а информируя пользователя.
5. Success Metrics / Validation Criteria
MVP:
Приложение успешно запускается на целевых ОС (например, Windows 10/11, macOS).
Потребление CPU в активном режиме не превышает 15-20%.
Пользователь может успешно пройти процесс калибровки.
Индикатор статуса корректно реагирует на изменение положения головы пользователя с задержкой не более 1 секунды.
Будущие версии:
Положительные отзывы пользователей о пользе уведомлений.
Статистические данные, собираемые приложением, показывают увеличение доли времени с "правильной" осанкой у активных пользователей.
6. Assumptions Made
У пользователя есть работающая веб-камера, и он предоставит приложению доступ к ней.
Для MVP достаточно простого анализа по вертикальной оси головы. Сложные случаи (наклон, поворот) не рассматриваются.
Пользователь сидит относительно неподвижно перед камерой. Приложение не предназначено для использования в движении.
Команда разработки обладает компетенциями в выбранном технологическом стеке.
7. Open Questions / Areas for Further Investigation
Какую платформу (Windows, macOS, Linux) выбрать в качестве основной для MVP?
Каков должен быть "порог терпимости" (tolerance) в пикселях для определения отклонения от правильной осанки? Стоит ли делать его настраиваемым?
Как именно реализовать процесс калибровки, чтобы он был максимально понятен для нетехнического пользователя? (Например, нарисовать контур-подсказку на видео).
Требуется ли поддержка нескольких камер? (Предполагается, что нет для MVP).
